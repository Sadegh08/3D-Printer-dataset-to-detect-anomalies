{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Notebook for Training 3D printer dataset\n","\n","> This notebook is mainly adapted from [OpenAI work](https://github.com/gabrielhuang/reptile-pytorch)"],"metadata":{"id":"II1UADPhN6Y0"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lq1eSwgxjeAR","executionInfo":{"status":"ok","timestamp":1681943569028,"user_tz":-210,"elapsed":48016,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"2fb1ce57-46c9-4581-9edd-7545116afaf7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Crop version\n","!pip install timm\n","!pip install gdown==4.4.0\n","!gdown 1Fq0DkvzoB3wI6a8IgPeYplD01c-WmXvn -O tmp.zip && unzip -q tmp.zip && rm tmp.zip"],"metadata":{"id":"u6AcReMXnjnE","outputId":"f4d75379-e75b-44d1-8f94-be7f84c7a807","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681943585214,"user_tz":-210,"elapsed":16189,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (2.0.0+cu118)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.15.1+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (6.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (1.11.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2.27.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (1.22.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","Installing collected packages: huggingface-hub, timm\n","Successfully installed huggingface-hub-0.13.4 timm-0.6.13\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gdown==4.4.0\n","  Downloading gdown-4.4.0.tar.gz (14 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown==4.4.0) (2.27.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown==4.4.0) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown==4.4.0) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown==4.4.0) (4.11.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown==4.4.0) (3.11.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown==4.4.0) (2.4.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown==4.4.0) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown==4.4.0) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown==4.4.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown==4.4.0) (2.0.12)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown==4.4.0) (1.7.1)\n","Building wheels for collected packages: gdown\n","  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14776 sha256=284aeb1e1f15dad7e14b706268338fc086e43125bec98a51005ac77a026ec7de\n","  Stored in directory: /root/.cache/pip/wheels/7d/37/b6/b2a79c75e898c0b8e46ff255102602d7159a10d9af0d80641a\n","Successfully built gdown\n","Installing collected packages: gdown\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.6.6\n","    Uninstalling gdown-4.6.6:\n","      Successfully uninstalled gdown-4.6.6\n","Successfully installed gdown-4.4.0\n","Access denied with the following error:\n","\n"," \tCannot retrieve the public link of the file. You may need to change\n","\tthe permission to 'Anyone with the link', or have had many accesses. \n","\n","You may still be able to access the file from the browser:\n","\n","\t https://drive.google.com/uc?id=1Fq0DkvzoB3wI6a8IgPeYplD01c-WmXvn \n","\n"]}]},{"cell_type":"code","source":["import os\n","import glob\n","import random\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","\n","import torchvision\n","from torchvision.utils import make_grid\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","\n","import timm\n","from tqdm import tqdm\n","\n","from PIL import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","from matplotlib import cm \n","\n","from sklearn.metrics import f1_score, accuracy_score"],"metadata":{"id":"M1B6ozRKoZBS","execution":{"iopub.status.busy":"2022-06-14T02:14:50.466116Z","iopub.execute_input":"2022-06-14T02:14:50.46648Z","iopub.status.idle":"2022-06-14T02:14:57.408317Z","shell.execute_reply.started":"2022-06-14T02:14:50.466448Z","shell.execute_reply":"2022-06-14T02:14:57.407361Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943590807,"user_tz":-210,"elapsed":5596,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Creat training and testing validation"],"metadata":{"id":"91dy0zCCoQUQ"}},{"cell_type":"code","source":["random.seed(0)\n","\n","# Set up training dataset\n","train_no_defect = [\n","    file for file in glob.glob(\"/content/drive/MyDrive/Python/Mohammad_Sadegh_Javadi(Session_1)/Documentation/no_defected/*.jpg\") if \"scratch_2\" not in file]\n","train_yes_defect = [\n","    file for file in glob.glob(\"/content/drive/MyDrive/Python/Mohammad_Sadegh_Javadi(Session_1)/Documentation/defected/*.jpg\") if \"no_bottom\" not in file\n","]\n","train_yes_defect = random.choices(train_yes_defect, k=len(train_no_defect))\n","\n","# Set up validation dataset\n","val_no_defect = [\n","    file for file in glob.glob(\"/content/drive/MyDrive/Python/Mohammad_Sadegh_Javadi(Session_1)/Documentation/no_defected/*.jpg\") if \"scratch_2\" in file]\n","val_yes_defect = [\n","    file for file in glob.glob(\"/content/drive/MyDrive/Python/Mohammad_Sadegh_Javadi(Session_1)/Documentation/defected/*.jpg\") if \"no_bottom\" in file]"],"metadata":{"id":"DpJ4-A3CoU8o","execution":{"iopub.status.busy":"2022-06-14T02:14:57.410461Z","iopub.execute_input":"2022-06-14T02:14:57.411437Z","iopub.status.idle":"2022-06-14T02:14:57.43009Z","shell.execute_reply.started":"2022-06-14T02:14:57.411395Z","shell.execute_reply":"2022-06-14T02:14:57.429418Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943598492,"user_tz":-210,"elapsed":7689,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Explore the data"],"metadata":{"id":"RnuShA8zfS0n"}},{"cell_type":"code","source":["# Count the number of the the class\n","# Training\n","count_train_no_defect = len(train_no_defect)\n","count_train_defect = len(train_yes_defect)\n","\n","# Validation\n","count_val_no_defect = len(val_no_defect)\n","count_val_defect = len(val_yes_defect)"],"metadata":{"id":"6079R3QnfVTa","execution":{"iopub.status.busy":"2022-06-14T02:14:57.431252Z","iopub.execute_input":"2022-06-14T02:14:57.431737Z","iopub.status.idle":"2022-06-14T02:14:57.436316Z","shell.execute_reply.started":"2022-06-14T02:14:57.431692Z","shell.execute_reply":"2022-06-14T02:14:57.435357Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943598493,"user_tz":-210,"elapsed":4,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure(figsize=(8, 6))\n","ax = fig.add_subplot(111)\n","\n","# Set up title and and x label\n","x_title = [\"training\", \"validation\"]\n","no_defect_score = [count_train_no_defect, count_val_no_defect]\n","defect_score = [count_train_defect, count_val_defect]\n","x = np.arange(len(x_title))\n","width = 0.3\n","\n","# Plot the data\n","bar1 = ax.bar(x, no_defect_score, width, color=\"#D67D3E\", label=\"no defect\")\n","bar2 = ax.bar(x + width, defect_score, width, color=\"#F9E4D4\", label=\"defect\")\n","\n","# Add heights above the bar plot\n","for rect, height in zip(bar1 + bar2, no_defect_score + defect_score):\n","    height = rect.get_height()\n","    plt.text(\n","        rect.get_x() + rect.get_width() / 2.0, height + 2,\n","        f\"{height:.0f}\", ha=\"center\", va=\"bottom\")\n","\n","# Beautify the plot (optional)\n","ax.set_xticks(x + width / 2)\n","ax.set_xticklabels(x_title)\n","ax.set_yticks([])\n","ax.set_title(\"Distribution of dataset\")\n","ax.spines[\"right\"].set_visible(False)\n","ax.spines[\"top\"].set_visible(False)\n","ax.spines[\"left\"].set_visible(False)\n","\n","# Show the annotation to each bar\n","plt.legend()\n","plt.savefig(\"data.pdf\", transparent=True)"],"metadata":{"id":"S9vC2avXjDHw","execution":{"iopub.status.busy":"2022-06-14T02:14:57.437665Z","iopub.execute_input":"2022-06-14T02:14:57.438301Z","iopub.status.idle":"2022-06-14T02:14:57.982524Z","shell.execute_reply.started":"2022-06-14T02:14:57.438233Z","shell.execute_reply":"2022-06-14T02:14:57.981778Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"status":"ok","timestamp":1681943599933,"user_tz":-210,"elapsed":1443,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"ecbf5f9c-a185-4bc6-ea8a-e72a47a306fb"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Set up title and and x label\n","x_title = [\"training\", \"validation\"]\n","no_defect_score = [count_train_no_defect, count_val_no_defect]\n","defect_score = [count_train_defect, count_val_defect]\n","x = np.arange(len(x_title))\n","width = 0.3"],"metadata":{"id":"I6Zw7jVDCNWf","executionInfo":{"status":"ok","timestamp":1681943599934,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","fig = plt.figure(figsize=(16,12))\n","ax = fig.add_subplot(111)\n","\n","# Set up title and and x label\n","x_title = [\"training\", \"validation\"]\n","no_defect_score = [count_train_no_defect, count_val_no_defect]\n","defect_score = [count_train_defect, count_val_defect]\n","x = np.arange(len(x_title))\n","width = 0.3\n","\n","# Plot the data\n","bar1 = ax.bar(x, no_defect_score, width, color=\"#D67D3E\", label=\"no defect\")\n","bar2 = ax.bar(x + width, defect_score, width, color=\"#F9E4D4\", label=\"defect\")\n","\n","# Add heights above the bar plot\n","for rect, height in zip(bar1 + bar2, no_defect_score + defect_score):\n","    height = rect.get_height()\n","    plt.text(\n","        rect.get_x() + rect.get_width() / 2.0, height + 2,\n","        f\"{height:.0f}\", ha=\"center\", va=\"bottom\")\n","\n","# Beautify the plot (optional)\n","ax.set_xticks(x + width / 2)\n","ax.set_xticklabels(x_title)\n","ax.set_yticks([])\n","ax.set_title(\"Distribution of dataset\")\n","ax.spines[\"right\"].set_visible(False)\n","ax.spines[\"top\"].set_visible(False)\n","ax.spines[\"left\"].set_visible(False)\n","\n","# Show the annotation to each bar\n","plt.legend()\n","plt.savefig(\"data.pdf\", transparent=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"9sEb5_m3BKI9","executionInfo":{"status":"ok","timestamp":1681943599935,"user_tz":-210,"elapsed":22,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"acf01993-d8fd-4aac-ccb4-876433aa1b0f"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1600x1200 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# 0.75 no for acc\n","# Guess all samples to be 1 (yes defect)\n","print(\"Guess all yes defect\",\n","      f1_score([0]*count_val_no_defect + [1]*count_val_defect, [1] * (count_val_no_defect + count_val_defect), average=\"macro\"))\n","# Guess all samples to be 0 (no defect)\n","print(\"Guess all no defect\", \n","      f1_score([0]*count_val_no_defect + [1]*count_val_defect, [0]*(count_val_no_defect + count_val_defect), average=\"macro\"))"],"metadata":{"id":"5ku3Qa9VXXLm","outputId":"e08c552f-fc00-4cea-db4d-98f033c3e1fe","execution":{"iopub.status.busy":"2022-06-14T02:14:57.984974Z","iopub.execute_input":"2022-06-14T02:14:57.985489Z","iopub.status.idle":"2022-06-14T02:14:57.998812Z","shell.execute_reply.started":"2022-06-14T02:14:57.985453Z","shell.execute_reply":"2022-06-14T02:14:57.997836Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681943599935,"user_tz":-210,"elapsed":18,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Guess all yes defect 0.19393939393939394\n","Guess all no defect 0.43162393162393164\n"]}]},{"cell_type":"markdown","source":["## Create Meta Dataset"],"metadata":{"id":"i5MeSYQ7rQjJ"}},{"cell_type":"code","source":["class FewShotDataset(Dataset):\n","    def __init__(self, img_list, transform):\n","        self.img_list = img_list\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_list)\n","    \n","    def __getitem__(self, idx):\n","        label, path = self.img_list[idx]\n","        img = Image.open(path)\n","        img = self.transform(img)\n","        return img, label"],"metadata":{"id":"EPfwPPyAqj3D","execution":{"iopub.status.busy":"2022-06-14T02:14:58.000068Z","iopub.execute_input":"2022-06-14T02:14:58.000525Z","iopub.status.idle":"2022-06-14T02:14:58.007239Z","shell.execute_reply.started":"2022-06-14T02:14:58.00049Z","shell.execute_reply":"2022-06-14T02:14:58.006365Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943599936,"user_tz":-210,"elapsed":11,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class MetaPrinterFolder:\n","    def __init__(self, no_defect, yes_defect, \n","                 train_transform=None, val_transform=None):\n","        self.no_defect = no_defect\n","        self.yes_defect = yes_defect\n","        self.train_transform = train_transform\n","        self.val_transform = val_transform\n","        \n","    def get_random_task(self, K=1):\n","        train_task, _ = self.get_random_task_split(train_K=K, test_K=0)\n","        return train_task\n","\n","    def get_random_task_split(self, train_K=1, test_K=1):\n","        train_samples = []\n","        test_samples = []\n","        \n","        sample_num = train_K + test_K\n","        # ====== Good list =======\n","        for idx, path in enumerate(np.random.choice(self.no_defect, sample_num, replace=False)): \n","                                                    \n","            if idx < train_K:\n","                train_samples.append((0, path))\n","            else:\n","                test_samples.append((0, path))\n","\n","        # ====== Bad list =======\n","        for i, path in enumerate(np.random.choice(self.yes_defect, sample_num, replace=False)):\n","            if i < train_K:\n","                train_samples.append((1, path))\n","            else:\n","                test_samples.append((1, path))\n","\n","        train_task = FewShotDataset(train_samples, self.train_transform)\n","        test_task = FewShotDataset(test_samples, self.val_transform)\n","                             \n","        return train_task, test_task"],"metadata":{"id":"T4Nlo8bYj7_n","execution":{"iopub.status.busy":"2022-06-14T02:14:58.008841Z","iopub.execute_input":"2022-06-14T02:14:58.009385Z","iopub.status.idle":"2022-06-14T02:14:58.026839Z","shell.execute_reply.started":"2022-06-14T02:14:58.009334Z","shell.execute_reply":"2022-06-14T02:14:58.025952Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600636,"user_tz":-210,"elapsed":710,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["filenames = glob.glob(os.path.join('/stim/','line*.png'))\n","\n","# DEBUG:\n","print(filenames)\n","\n","# need to start with an empty list\n","images = []\n","# create an image stimulus from each file, and store in the list:\n","for file in filenames:\n","    images.append(visual.ImageStim(win=win, image=file))\n","\n","# DEBUG:\n","print(images)"],"metadata":{"id":"Arb1TI9tfTMd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681943600638,"user_tz":-210,"elapsed":22,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"41a3423d-c5e0-42fa-f348-c01d072cfd90"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n","[]\n"]}]},{"cell_type":"code","source":["demo_transform = transforms.Compose([transforms.ToTensor(),\n","    transforms.Resize((400, 400)),\n","    transforms.CenterCrop((352, 352)),\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n","])\n"," \n","meta_3d_printer = MetaPrinterFolder(\n","    train_no_defect, train_yes_defect, demo_transform, demo_transform)\n","train_task = meta_3d_printer.get_random_task()"],"metadata":{"id":"PKyBgMukrKvZ","execution":{"iopub.status.busy":"2022-06-14T02:14:58.028281Z","iopub.execute_input":"2022-06-14T02:14:58.028608Z","iopub.status.idle":"2022-06-14T02:14:58.044592Z","shell.execute_reply.started":"2022-06-14T02:14:58.028576Z","shell.execute_reply":"2022-06-14T02:14:58.043435Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600639,"user_tz":-210,"elapsed":19,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Create Model"],"metadata":{"id":"owLz-qPcc3So"}},{"cell_type":"code","source":["class ReptileModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def point_grad_to(self, target):\n","        self.zero_grad()\n","        for p, target_p in zip(self.parameters(), target.parameters()):\n","            if p.grad is None:\n","                if self.is_cuda():\n","                    p.grad = torch.zeros(p.size()).cuda()\n","                else:\n","                    p.grad = torch.zeros(p.size())\n","            p.grad.data.add_(p.data - target_p.data)\n","\n","    def is_cuda(self):\n","        return next(self.parameters()).is_cuda"],"metadata":{"id":"FOx_RL_mc5ME","execution":{"iopub.status.busy":"2022-06-14T02:14:58.046212Z","iopub.execute_input":"2022-06-14T02:14:58.046605Z","iopub.status.idle":"2022-06-14T02:14:58.061516Z","shell.execute_reply.started":"2022-06-14T02:14:58.046571Z","shell.execute_reply":"2022-06-14T02:14:58.060549Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600639,"user_tz":-210,"elapsed":18,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class TrainModel(ReptileModel):\n","    def __init__(self, model_name=\"resnet34\", pretrained=True, num_classes=2):\n","        super().__init__()\n","        \n","        # Model settings\n","        self.model_name = model_name\n","        self.pretrained=pretrained\n","        self.num_classes = num_classes\n","\n","        # Check out the doc: https://rwightman.github.io/pytorch-image-models/\n","        #  for different models\n","        self.model = timm.create_model(model_name, pretrained=pretrained)\n","        \n","        # Change the output linear layers to fit the output classes\n","        self.model.fc = nn.Linear(\n","            self.model.fc.weight.shape[1],\n","            num_classes\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def clone(self):\n","        clone = TrainModel(self.model_name, self.pretrained, self.num_classes)\n","        clone.load_state_dict(self.state_dict())\n","        if self.is_cuda():\n","            clone.cuda()\n","        return clone"],"metadata":{"id":"adAvF4PcdHLd","execution":{"iopub.status.busy":"2022-06-14T02:14:58.064425Z","iopub.execute_input":"2022-06-14T02:14:58.066148Z","iopub.status.idle":"2022-06-14T02:14:58.073585Z","shell.execute_reply.started":"2022-06-14T02:14:58.066124Z","shell.execute_reply":"2022-06-14T02:14:58.072786Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600639,"user_tz":-210,"elapsed":17,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## Set up training pipe"],"metadata":{"id":"RIypzX3lsimZ"}},{"cell_type":"code","source":["@torch.no_grad()\n","def evaluate(model, val_loader, args):\n","    model.eval()\n","\n","    total_predict = []\n","    total_ground_truth = []\n","    for iteration in range(args.iterations):\n","        data, label = val_loader.__next__()\n","        data = data.to(args.device)\n","        label = label.to(args.device)\n","\n","        output = model(data)\n","        prediction = output.argmax(dim=-1)\n","\n","        total_predict.extend(prediction.cpu().tolist())\n","        total_ground_truth.extend(label.cpu().tolist())\n","\n","    return accuracy_score(total_ground_truth, total_predict), \\\n","           f1_score(total_ground_truth, total_predict, average=\"macro\")"],"metadata":{"id":"htm7Q1SRsmQJ","execution":{"iopub.status.busy":"2022-06-14T02:14:58.074793Z","iopub.execute_input":"2022-06-14T02:14:58.075272Z","iopub.status.idle":"2022-06-14T02:14:58.084944Z","shell.execute_reply.started":"2022-06-14T02:14:58.075238Z","shell.execute_reply":"2022-06-14T02:14:58.084039Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600640,"user_tz":-210,"elapsed":17,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def train_iter(model, train_loader, criterion, optimizer, args):\n","    model.train()\n","    for iteration in range(args.iterations):\n","        data, label = train_loader.__next__()\n","        data = data.to(args.device)\n","        label = label.to(args.device)\n","\n","        # Send data into the model and compute the loss\n","        output = model(data)\n","        loss = criterion(output, label)\n","\n","        # Update the model with back propagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    return loss.item()"],"metadata":{"id":"HtAbMcfKsiO8","execution":{"iopub.status.busy":"2022-06-14T02:14:58.086305Z","iopub.execute_input":"2022-06-14T02:14:58.086902Z","iopub.status.idle":"2022-06-14T02:14:58.096058Z","shell.execute_reply.started":"2022-06-14T02:14:58.086835Z","shell.execute_reply":"2022-06-14T02:14:58.095243Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600640,"user_tz":-210,"elapsed":17,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def get_optimizer(net, args, state=None):\n","    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n","    if state is not None:\n","        optimizer.load_state_dict(state)\n","    return optimizer"],"metadata":{"id":"DaSgvXrztVct","execution":{"iopub.status.busy":"2022-06-14T02:14:58.097249Z","iopub.execute_input":"2022-06-14T02:14:58.097618Z","iopub.status.idle":"2022-06-14T02:14:58.104513Z","shell.execute_reply.started":"2022-06-14T02:14:58.097583Z","shell.execute_reply":"2022-06-14T02:14:58.103791Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600640,"user_tz":-210,"elapsed":16,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def set_learning_rate(optimizer, lr):\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr"],"metadata":{"id":"-CyTWpW5tbf5","execution":{"iopub.status.busy":"2022-06-14T02:14:58.108951Z","iopub.execute_input":"2022-06-14T02:14:58.109199Z","iopub.status.idle":"2022-06-14T02:14:58.114807Z","shell.execute_reply.started":"2022-06-14T02:14:58.109172Z","shell.execute_reply":"2022-06-14T02:14:58.112369Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600641,"user_tz":-210,"elapsed":16,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def make_infinite(dataloader):\n","    while True:\n","        for x in dataloader:\n","            yield x"],"metadata":{"id":"Mdx3big2_Q0I","execution":{"iopub.status.busy":"2022-06-14T02:14:58.116271Z","iopub.execute_input":"2022-06-14T02:14:58.116929Z","iopub.status.idle":"2022-06-14T02:14:58.121285Z","shell.execute_reply.started":"2022-06-14T02:14:58.116892Z","shell.execute_reply":"2022-06-14T02:14:58.120484Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600641,"user_tz":-210,"elapsed":16,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def meta_train_reptile(args, meta_model, meta_train, meta_test, meta_optimizer, criterion):\n","    for meta_iteration in tqdm(range(args.start_meta_iteration, args.meta_iterations)):\n","        # Update learning rate\n","        meta_lr = args.meta_lr * (1. - meta_iteration / float(args.meta_iterations))\n","        set_learning_rate(meta_optimizer, meta_lr)\n","\n","        # Clone model\n","        net = meta_model.clone()\n","        optimizer = get_optimizer(net, args)\n","\n","        # Sample base task from Meta-Train\n","        train_dataset = meta_train.get_random_task(args.train_shots)\n","        infinite_train_loader = make_infinite(\n","            DataLoader(\n","                train_dataset, args.batch_size, shuffle=True,\n","                num_workers=2, pin_memory=True))\n","\n","        # Update fast net\n","        train_iter(net, infinite_train_loader, criterion, optimizer, args)\n","\n","        # Update slow net\n","        meta_model.point_grad_to(net)\n","        meta_optimizer.step()\n","\n","        # Meta-Evaluation\n","        if meta_iteration % args.validate_every == 0:\n","            for (meta_dataset, mode) in [(meta_test, \"val\")]:\n","                train, test = meta_dataset.get_random_task_split(\n","                    train_K=args.shots, test_K=5)\n","                infinite_train_loader = make_infinite(\n","                    DataLoader(\n","                        train, args.batch_size, shuffle=True,\n","                        num_workers=2, pin_memory=True))\n","                infinite_test_loader = make_infinite(\n","                    DataLoader(\n","                        test, args.batch_size, shuffle=True,\n","                        num_workers=2, pin_memory=True))\n","\n","                # Base-train\n","                net = meta_model.clone()\n","                optimizer = get_optimizer(net, args)\n","                train_iter(\n","                    net, infinite_train_loader, criterion, optimizer, args)\n","\n","                # Base-test: compute meta-loss, which is base-validation error\n","                meta_acc, meta_f1 = evaluate(net, infinite_test_loader, args)\n","                print(f\"\\n{mode}: f1-accuracy: {meta_f1:.3f}, acc: {meta_acc:.3f}\")\n","\n","        if meta_iteration % args.check_every == 0:\n","            torch.save(meta_model.state_dict(), \"cur.pt\")"],"metadata":{"id":"DvI81fJD-Y6M","execution":{"iopub.status.busy":"2022-06-14T02:14:58.12267Z","iopub.execute_input":"2022-06-14T02:14:58.1234Z","iopub.status.idle":"2022-06-14T02:14:58.136262Z","shell.execute_reply.started":"2022-06-14T02:14:58.123288Z","shell.execute_reply":"2022-06-14T02:14:58.135465Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600641,"user_tz":-210,"elapsed":15,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Combine all"],"metadata":{"id":"mep71RznuRvb"}},{"cell_type":"code","source":["class args:\n","    # Training\n","    epochs = 30\n","    batch_size = 32\n","    train_shots = 10\n","    shots = 5\n","    meta_iterations = 1000\n","    start_meta_iteration = 0\n","    iterations = 5\n","    test_iterations = 50\n","    meta_lr = 0.1\n","    validate_every = 50\n","    check_every = 100\n","    lr = 3e-4\n","    weight_decay=1e-5\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    # Transform\n","    size = 400\n","    crop_size = 352\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]"],"metadata":{"id":"aLfa3vuLruxq","execution":{"iopub.status.busy":"2022-06-14T02:14:58.137563Z","iopub.execute_input":"2022-06-14T02:14:58.13795Z","iopub.status.idle":"2022-06-14T02:14:58.195008Z","shell.execute_reply.started":"2022-06-14T02:14:58.137916Z","shell.execute_reply":"2022-06-14T02:14:58.193956Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600642,"user_tz":-210,"elapsed":15,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Set up train loader and test loader\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((args.size, args.size)),\n","    transforms.CenterCrop((args.crop_size, args.crop_size)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.Normalize(mean=args.mean, std=args.std)\n","])\n","val_transform = transforms.Compose([\n","    transforms.ToTensor(),                                    \n","    transforms.Resize((args.size, args.size)),\n","    transforms.CenterCrop((args.crop_size, args.crop_size)),\n","    transforms.Normalize(mean=args.mean, std=args.std)\n","])"],"metadata":{"id":"EVIpM7cFCros","execution":{"iopub.status.busy":"2022-06-14T02:14:58.196064Z","iopub.execute_input":"2022-06-14T02:14:58.196424Z","iopub.status.idle":"2022-06-14T02:14:58.206928Z","shell.execute_reply.started":"2022-06-14T02:14:58.19639Z","shell.execute_reply":"2022-06-14T02:14:58.206167Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943600642,"user_tz":-210,"elapsed":15,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Set up model\n","meta_model = TrainModel().to(args.device)\n","criterion = nn.CrossEntropyLoss()\n","meta_optimizer = torch.optim.SGD(\n","    meta_model.parameters(), lr=args.meta_lr)"],"metadata":{"id":"nNGkRNBaCtXw","execution":{"iopub.status.busy":"2022-06-14T02:14:58.208512Z","iopub.execute_input":"2022-06-14T02:14:58.209108Z","iopub.status.idle":"2022-06-14T02:15:06.414168Z","shell.execute_reply.started":"2022-06-14T02:14:58.209074Z","shell.execute_reply":"2022-06-14T02:15:06.413307Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681943614365,"user_tz":-210,"elapsed":13737,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"4c342492-b025-4ef1-9365-26ecbdac237d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-43635321.pth\n"]}]},{"cell_type":"code","source":["meta_train = MetaPrinterFolder(\n","    train_no_defect, train_yes_defect, train_transform, val_transform)\n","meta_test = MetaPrinterFolder(\n","    val_no_defect, val_yes_defect, train_transform, val_transform)"],"metadata":{"id":"Ugh-_rXWIId3","execution":{"iopub.status.busy":"2022-06-14T02:15:06.415433Z","iopub.execute_input":"2022-06-14T02:15:06.415823Z","iopub.status.idle":"2022-06-14T02:15:06.420598Z","shell.execute_reply.started":"2022-06-14T02:15:06.415788Z","shell.execute_reply":"2022-06-14T02:15:06.419589Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681943614367,"user_tz":-210,"elapsed":7,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Start training\n","meta_train_reptile(args, meta_model, meta_train, meta_test, meta_optimizer, criterion)"],"metadata":{"id":"gnO6Wd8rITCE","execution":{"iopub.status.busy":"2022-06-14T02:15:06.422005Z","iopub.execute_input":"2022-06-14T02:15:06.423449Z","iopub.status.idle":"2022-06-14T03:09:03.15635Z","shell.execute_reply.started":"2022-06-14T02:15:06.423412Z","shell.execute_reply":"2022-06-14T03:09:03.154636Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1kyvUk0Q7tRNVpM3urt56sr2SwG3EErwz"},"executionInfo":{"status":"ok","timestamp":1681948246155,"user_tz":-210,"elapsed":184293,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"0a7f9c99-9726-4276-ff5f-4ceb97d29501"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Used pretrained network to train on the whole dataset"],"metadata":{"id":"tvTwp9G5f-wA"}},{"cell_type":"code","source":["class ListDataset(Dataset):\n","    def __init__(self, yes_defect, no_defect, transform=None):\n","        self.img_list = yes_defect + no_defect\n","        self.label = [1] * len(yes_defect) + [0] * len(no_defect)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_list)\n","    \n","    def __getitem__(self, idx):\n","        img = Image.open(self.img_list[idx])\n","        label = self.label[idx]\n","        img = self.transform(img)\n","        return img, label"],"metadata":{"id":"uQ6aBFgUf-Ox","execution":{"iopub.status.busy":"2022-06-14T03:09:03.15837Z","iopub.execute_input":"2022-06-14T03:09:03.159008Z","iopub.status.idle":"2022-06-14T03:09:03.166659Z","shell.execute_reply.started":"2022-06-14T03:09:03.158966Z","shell.execute_reply":"2022-06-14T03:09:03.16557Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681948246156,"user_tz":-210,"elapsed":2,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def make_loader(yes_defect, no_defect, transform, batch_size,\n","                shuffle=True, num_workers=2, pin_memory=True,\n","                train=True):\n","    dataset = ListDataset(\n","        yes_defect=yes_defect, no_defect=no_defect, transform=transform)\n","    loader = DataLoader(\n","        dataset, batch_size=batch_size,\n","        num_workers=num_workers,\n","        shuffle=True,\n","        pin_memory=pin_memory)\n","    \n","    return loader"],"metadata":{"id":"QORqXvUTgQj0","execution":{"iopub.status.busy":"2022-06-14T03:09:03.16787Z","iopub.execute_input":"2022-06-14T03:09:03.168669Z","iopub.status.idle":"2022-06-14T03:09:03.17549Z","shell.execute_reply.started":"2022-06-14T03:09:03.168634Z","shell.execute_reply":"2022-06-14T03:09:03.174688Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681948246157,"user_tz":-210,"elapsed":3,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def post_train_evaluate(model, val_loader, args):\n","    model.eval()\n","\n","    total_predict = []\n","    total_ground_truth = []\n","    for data, label in val_loader:\n","        data = data.to(args.device)\n","        label = label.to(args.device)\n","\n","        output = model(data)\n","        prediction = output.argmax(dim=-1)\n","\n","        total_predict.extend(prediction.cpu().tolist())\n","        total_ground_truth.extend(label.cpu().tolist())\n","\n","    return accuracy_score(total_ground_truth, total_predict), \\\n","           f1_score(total_ground_truth, total_predict, average=\"macro\")"],"metadata":{"id":"KYKD7kFbgj6O","execution":{"iopub.status.busy":"2022-06-14T03:09:03.17689Z","iopub.execute_input":"2022-06-14T03:09:03.177261Z","iopub.status.idle":"2022-06-14T03:09:03.187179Z","shell.execute_reply.started":"2022-06-14T03:09:03.177228Z","shell.execute_reply":"2022-06-14T03:09:03.186314Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681948246157,"user_tz":-210,"elapsed":3,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def post_train(model, train_loader, val_loader, criterion, optimizer, args):\n","    best_f1 = 0\n","    for epoch in range(args.epochs):\n","        train_progress_bar = tqdm(\n","            train_loader, desc=f\"Epochs: {epoch + 1}/{args.epochs}\")\n","        \n","        model.train()\n","        for data, label in train_progress_bar:\n","            data = data.to(args.device)\n","            label = label.to(args.device)\n","\n","            # Send data into the model and compute the loss\n","            output = model(data)\n","            loss = criterion(output, label)\n","\n","            # Update the model with back propagation\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Compute the accuracy ans save the best model\n","        eval_acc, eval_f1 = post_train_evaluate(model, val_loader, args)\n","        print(f\"Validation accuracy: {eval_acc:.8f} f1-score: {eval_f1:.8f}\")\n","        if eval_f1 > best_f1:\n","            best_f1 = eval_f1\n","            torch.save(model.state_dict(), \"best.pt\")"],"metadata":{"id":"GpC_XmgNglyx","execution":{"iopub.status.busy":"2022-06-14T03:09:03.188546Z","iopub.execute_input":"2022-06-14T03:09:03.189094Z","iopub.status.idle":"2022-06-14T03:09:03.198535Z","shell.execute_reply.started":"2022-06-14T03:09:03.189055Z","shell.execute_reply":"2022-06-14T03:09:03.197664Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681948246158,"user_tz":-210,"elapsed":4,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["train_loader = make_loader(\n","    yes_defect=train_yes_defect, no_defect=train_no_defect,\n","    batch_size=args.batch_size,\n","    transform=train_transform)\n","val_loader = make_loader(\n","    yes_defect=val_yes_defect, no_defect=val_no_defect,\n","    batch_size=args.batch_size,\n","    transform=val_transform, train=False)"],"metadata":{"id":"uYb2Cw6igcEQ","execution":{"iopub.status.busy":"2022-06-14T03:09:03.200086Z","iopub.execute_input":"2022-06-14T03:09:03.200564Z","iopub.status.idle":"2022-06-14T03:09:03.207857Z","shell.execute_reply.started":"2022-06-14T03:09:03.200529Z","shell.execute_reply":"2022-06-14T03:09:03.207007Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681948246158,"user_tz":-210,"elapsed":4,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["meta_model.load_state_dict(torch.load(\"cur.pt\"))\n","train_model = meta_model.clone()\n","criterion = nn.CrossEntropyLoss()\n","train_optimizer = torch.optim.Adam(train_model.parameters(), lr=args.lr)"],"metadata":{"id":"R_te_psxfzw3","execution":{"iopub.status.busy":"2022-06-14T03:09:03.209215Z","iopub.execute_input":"2022-06-14T03:09:03.20962Z","iopub.status.idle":"2022-06-14T03:09:03.790108Z","shell.execute_reply.started":"2022-06-14T03:09:03.209588Z","shell.execute_reply":"2022-06-14T03:09:03.789302Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1681948247057,"user_tz":-210,"elapsed":903,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Start training\n","post_train(train_model, train_loader, val_loader, criterion, train_optimizer, args)\n","torch.save(train_model.state_dict(), \"last.pt\")"],"metadata":{"id":"fs5PeIH6gi4S","execution":{"iopub.status.busy":"2022-06-14T03:09:03.791481Z","iopub.execute_input":"2022-06-14T03:09:03.791842Z","iopub.status.idle":"2022-06-14T03:15:54.010469Z","shell.execute_reply.started":"2022-06-14T03:09:03.791807Z","shell.execute_reply":"2022-06-14T03:15:54.009504Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681948938356,"user_tz":-210,"elapsed":691304,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"194851c1-4bd1-4aed-8ff4-8eea7934db23"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["\rEpochs: 1/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 1/30: 100%|██████████| 32/32 [00:14<00:00,  2.22it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 0.99749373 f1-score: 0.99658288\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 2/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 2/30: 100%|██████████| 32/32 [00:15<00:00,  2.12it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 3/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 3/30: 100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 4/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 4/30: 100%|██████████| 32/32 [00:14<00:00,  2.22it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 5/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 5/30: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 6/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 6/30: 100%|██████████| 32/32 [00:16<00:00,  1.97it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 7/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 7/30: 100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 8/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 8/30: 100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 9/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 9/30: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 10/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 10/30: 100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 11/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 11/30: 100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 12/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 12/30: 100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 13/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 13/30: 100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 14/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 14/30: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 15/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 15/30: 100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 16/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 16/30: 100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 17/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 17/30: 100%|██████████| 32/32 [00:15<00:00,  2.12it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 18/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 18/30: 100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 19/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 19/30: 100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 20/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 20/30: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 21/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 21/30: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 22/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 22/30: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 23/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 23/30: 100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 24/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 24/30: 100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 25/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 25/30: 100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 26/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 26/30: 100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 27/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 27/30: 100%|██████████| 32/32 [00:15<00:00,  2.12it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 28/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 28/30: 100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 29/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 29/30: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs: 30/30:   0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","Epochs: 30/30: 100%|██████████| 32/32 [00:14<00:00,  2.14it/s]\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 1.00000000 f1-score: 1.00000000\n"]}]},{"cell_type":"markdown","source":["## Model Explanation"],"metadata":{"id":"9D0hKqFmrOXN"}},{"cell_type":"code","source":["class GradCAM:\n","    def __init__(self, model, layer_name, img_size):\n","        self.model = model\n","        self.layer_name = layer_name\n","        self.img_size = img_size\n","\n","        # Save the forward and backward features\n","        self.module_list = []\n","        self.features_list = dict()\n","        self.gradient_list = dict()\n","\n","        # Handlers list\n","        self.handlers = []\n","        self._register_hook()\n","\n","        self.img_transform =  transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Resize((400, 400)),\n","            transforms.CenterCrop((img_size, img_size)),\n","            transforms.Normalize(\n","                mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225]\n","            )\n","        ])\n","\n","    def activation_name(self, name, hook_type):\n","        def _get_hook(module, input, output):\n","            if hook_type == \"forward\":\n","                self.module = name\n","                self.features_list[name] = output\n","            elif hook_type == \"backward\":\n","                self.gradient_list[name] = output[0]\n","            else:\n","                raise ValueError(f\"Nor supported hook type: {hook_type}\")\n","        return _get_hook\n","\n","    def _clear_list(self):\n","        self.module = None\n","        self.features_list = dict()\n","        self.gradient_list = dict()\n","\n","    def _register_hook(self):\n","        self.handlers = []\n","        for (name, module) in self.model.named_modules():\n","            if name == self.layer_name:\n","                self.handlers.append(\n","                    module.register_forward_hook(\n","                        self.activation_name(name, \"forward\")\n","                    )\n","                )\n","                self.handlers.append(\n","                    module.register_full_backward_hook(\n","                        self.activation_name(name, \"backward\")\n","                    )\n","                )\n","    \n","    def remove_handlers(self):\n","        for handle in self.handlers:\n","            handle.remove()\n","\n","    def __call__(self, img, device):\n","        # Clear the list\n","        self._clear_list()\n","\n","        ori_size = img.shape[:2][::-1]\n","        in_features = self.img_transform(img).to(device)\n","        \n","        res = self.model(in_features.unsqueeze(0)).view(-1)\n","        \n","        self.model.zero_grad()\n","        predict_cls = res.argmax(dim=-1).item()\n","        target = res[predict_cls]\n","        target.backward()\n","\n","        gradient = self.gradient_list[self.module].data[0]\n","        weight = torch.mean(gradient, dim=(1, 2), keepdim=True)\n","\n","        feature = self.features_list[self.module].data[0]\n","        temp_cam = (feature * weight).sum(dim=0).relu()\n","\n","        # Normalize the value\n","        temp_cam -= torch.min(temp_cam)\n","        temp_cam /= torch.max(temp_cam)\n","\n","        temp_cam = cv2.resize(\n","            temp_cam.detach().cpu().numpy(), ori_size)\n","        heatmap = (cm.jet(temp_cam)[..., :3] * 255).astype(\"uint8\")\n","        temp_cam = (img * 0.5 + heatmap * 0.5).astype(\"uint8\")\n","\n","        return temp_cam, predict_cls"],"metadata":{"id":"xxgTDp_vE5eJ","executionInfo":{"status":"ok","timestamp":1681950748871,"user_tz":-210,"elapsed":728,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["def save_grad_cam(model, target_layer, img_list, weight_file, save_path, args):\n","    # if save_path == img_root:\n","    #     raise ValueError(\"Save path should not be the same with image root, \" \n","    #                      \"otherwise the original data will be overwritten\")\n","    os.makedirs(save_path, exist_ok=True)\n","\n","    # Define the model and grad cam instance\n","    new_model = model.clone()\n","    new_model.load_state_dict(torch.load(weight_file))\n","    grad_cam = GradCAM(new_model, target_layer, args.crop_size)\n","\n","    for img_path in tqdm(img_list):\n","        img = cv2.imread(img_path)\n","\n","        # Get grad cam image and save it\n","        res, pred = grad_cam(img, args.device)\n","        cv2.imwrite(f\"{save_path}/{pred}_{os.path.basename(img_path)}\", res)\n","\n","    grad_cam.remove_handlers()"],"metadata":{"id":"ifOeNdgPE8Kq","executionInfo":{"status":"ok","timestamp":1681950770853,"user_tz":-210,"elapsed":698,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["save_grad_cam(\n","    model=train_model, target_layer=\"model.layer4.2.conv2\",\n","    img_list=val_yes_defect + val_no_defect, \n","    weight_file=\"best.pt\", save_path=\"cam_image\",\n","    args=args\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVxe0rCqE8No","executionInfo":{"status":"ok","timestamp":1681950811428,"user_tz":-210,"elapsed":27542,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"b4734d93-6c7c-4395-aaa5-556fb32e117e"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 399/399 [00:26<00:00, 15.10it/s]\n"]}]},{"cell_type":"markdown","source":["## ONNX\n","\n","| model |  time |\n","|: --- :|: --- :|\n","| torch | 0.253 |\n","| onnx  | 0.037 |"],"metadata":{"id":"ZaB2-i-pbHXf"}},{"cell_type":"code","source":["!pip install onnx onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OrQQPqqsFIlM","executionInfo":{"status":"ok","timestamp":1681950818652,"user_tz":-210,"elapsed":4779,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"6d54248d-1533-47ea-b2c4-e56fd5631675"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: onnx in /usr/local/lib/python3.9/dist-packages (1.13.1)\n","Requirement already satisfied: onnxruntime in /usr/local/lib/python3.9/dist-packages (1.14.1)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx) (1.22.4)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx) (4.5.0)\n","Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx) (3.20.3)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (1.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.3.3)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.9/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime) (1.3.0)\n"]}]},{"cell_type":"code","source":["import onnx\n","import onnxruntime as ort"],"metadata":{"id":"CbdOb1PVP_P-","executionInfo":{"status":"ok","timestamp":1681950830718,"user_tz":-210,"elapsed":5,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# Transform the pytorch model to onnx\n","dummy_input = torch.randn(1, 3, 352, 352, device=\"cuda\")\n","\n","input_names = [\"input\"]\n","output_names = [\"output\"]\n","\n","train_model.load_state_dict(torch.load(\"best.pt\"))\n","train_model.eval()\n","torch.onnx.export(train_model, dummy_input, \"resnet.onnx\",\n","                  input_names=input_names, output_names=output_names,\n","                  opset_version=12)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4uNTGOLnFPnT","executionInfo":{"status":"ok","timestamp":1681950846656,"user_tz":-210,"elapsed":3378,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"06859092-6d81-44db-c013-b44c3f5bc62c"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n"]}]},{"cell_type":"code","source":["# Load the ONNX model\n","model = onnx.load(\"resnet.onnx\")\n","\n","# Check that the model is well formed\n","onnx.checker.check_model(model)"],"metadata":{"id":"XKgBx3b9FPqK","executionInfo":{"status":"ok","timestamp":1681950856793,"user_tz":-210,"elapsed":721,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Check accuracy of ONNX model\n","\n","# Load model\n","ort_session = ort.InferenceSession(\"resnet.onnx\")\n","\n","total_correct = []\n","total_predict = []\n","\n","img_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((args.size, args.size)),\n","    transforms.CenterCrop((args.crop_size, args.crop_size)),\n","    transforms.Normalize(mean=args.mean, std=args.std),\n","    transforms.Lambda(lambda x: x.unsqueeze(0).numpy())\n","])\n","\n","ground_truth = [1] * len(val_yes_defect) + [0] * len(val_no_defect)\n","for label, img_path in zip(ground_truth, val_yes_defect + val_no_defect):\n","    # Read in image\n","    img = Image.open(img_path)\n","    \n","    outputs = ort_session.run(None, {\"input\": img_transform(img)})\n","    \n","    total_correct.append(label)\n","    total_predict.append(int(outputs[0][0][1] > outputs[0][0][0]))"],"metadata":{"id":"DZw5RftfFPsw","executionInfo":{"status":"ok","timestamp":1681950943189,"user_tz":-210,"elapsed":75198,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["print(f\"ONNX, accuracy: {accuracy_score(total_correct, total_predict)} \"\n","      f\"f1_score: {f1_score(total_correct, total_predict)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5XibndicFPva","executionInfo":{"status":"ok","timestamp":1681950952559,"user_tz":-210,"elapsed":817,"user":{"displayName":"Mohammad sadegh javadi","userId":"11442396242895913244"}},"outputId":"40cbd47a-e594-4aab-9a6c-516f666da9ec"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["ONNX, accuracy: 1.0 f1_score: 1.0\n"]}]}]}